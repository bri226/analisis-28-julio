{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparar con DIFFLIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import difflib\n",
    "import re\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def normalize_text(text):\n",
    "    # Remueve caracteres especiales, extrae palabras y normaliza espacios\n",
    "    text = re.sub(r'[\\W_]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.lower()\n",
    "\n",
    "def compare_texts(text1, text2):\n",
    "    d = difflib.Differ()\n",
    "    diff = list(d.compare(text1.splitlines(), text2.splitlines()))\n",
    "    \n",
    "    # Calculate similarity\n",
    "    matcher = difflib.SequenceMatcher(None, text1, text2)\n",
    "    similarity = matcher.ratio() * 100\n",
    "\n",
    "    # Extract differences: + (added in IA), - (removed in IA)\n",
    "    additions = [line for line in diff if line.startswith('+ ')]\n",
    "    \n",
    "    return additions, similarity\n",
    "\n",
    "def save_differences(additions, similarity, output_path):\n",
    "    with open(output_path, 'w') as file:\n",
    "        file.write(f\"Similarity: {similarity:.2f}%\\n\")\n",
    "        file.write(\"Additions:\\n\")\n",
    "        for line in additions:\n",
    "            file.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison complete. Results saved to transcripcion/dinaboluarte/diff_output.txt\n"
     ]
    }
   ],
   "source": [
    "# Rutas a los archivos PDF\n",
    "official_pdf = \"transcripcion/dinaboluarte/2023_transcripcion_literal.pdf\"\n",
    "transcribed_pdf = \"transcripcion/dinaboluarte/2023_transcripcion_ia.pdf\"\n",
    "output_txt = \"transcripcion/dinaboluarte/diff_output.txt\"\n",
    "\n",
    "# Read the PDFs\n",
    "official_text = read_pdf(official_pdf)\n",
    "transcribed_text = read_pdf(transcribed_pdf)\n",
    "\n",
    "# Normalize the texts\n",
    "normalized_official_text = normalize_text(official_text)\n",
    "normalized_transcribed_text = normalize_text(transcribed_text)\n",
    "\n",
    "# Compare the texts\n",
    "differences, similarity = compare_texts(official_text, transcribed_text)\n",
    "\n",
    "# Compare the texts\n",
    "additions, similarity = compare_texts(normalized_official_text, normalized_transcribed_text)\n",
    "\n",
    "# Save the differences and similarity to a txt file\n",
    "save_differences(additions, similarity, output_txt)\n",
    "\n",
    "print(f\"Comparison complete. Results saved to {output_txt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparar con SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import spacy\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "\n",
    "# Load Spacy model\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def normalize_text(text):\n",
    "    # Normaliza el texto removiendo caracteres especiales y múltiples espacios\n",
    "    text = re.sub(r'[\\W_]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.lower()\n",
    "\n",
    "def compare_texts_spacy(text1, text2):\n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "\n",
    "    # Calculate similarity\n",
    "    similarity = doc1.similarity(doc2) * 100\n",
    "\n",
    "    # Compare texts using SequenceMatcher for more granular differences\n",
    "    matcher = SequenceMatcher(None, text1, text2)\n",
    "    diffs = matcher.get_opcodes()\n",
    "\n",
    "    additions = []\n",
    "    subtractions = []\n",
    "    for tag, i1, i2, j1, j2 in diffs:\n",
    "        if tag == 'insert':\n",
    "            additions.append(text2[j1:j2])\n",
    "        elif tag == 'delete':\n",
    "            subtractions.append(text1[i1:i2])\n",
    "        elif tag == 'replace':\n",
    "            subtractions.append(text1[i1:i2])\n",
    "            additions.append(text2[j1:j2])\n",
    "\n",
    "    return additions, subtractions, similarity\n",
    "\n",
    "def save_differences(additions, subtractions, similarity, output_path):\n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(f\"Similarity: {similarity:.2f}%\\n\\n\")\n",
    "        file.write(\"Additions:\\n\")\n",
    "        for line in additions:\n",
    "            file.write(f\"{line}\\n\")\n",
    "        file.write(\"\\nSubtractions:\\n\")\n",
    "        for line in subtractions:\n",
    "            file.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brillitt\\AppData\\Local\\Temp\\ipykernel_18640\\481312985.py:28: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity = doc1.similarity(doc2) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison complete. Results saved to transcripcion/dinaboluarte/diff_output.txt\n"
     ]
    }
   ],
   "source": [
    "# Paths to the PDF files\n",
    "official_pdf_path = \"transcripcion/dinaboluarte/2023_transcripcion_literal.pdf\"\n",
    "transcribed_pdf_path = \"transcripcion/dinaboluarte/2023_transcripcion_ia_2.pdf\"\n",
    "output_txt_path = \"transcripcion/dinaboluarte/diff_output.txt\"\n",
    "\n",
    "# Read the PDFs\n",
    "official_text = read_pdf(official_pdf_path)\n",
    "transcribed_text = read_pdf(transcribed_pdf_path)\n",
    "\n",
    "# Normalize the texts\n",
    "normalized_official_text = normalize_text(official_text)\n",
    "normalized_transcribed_text = normalize_text(transcribed_text)\n",
    "\n",
    "# Compare the texts using Spacy\n",
    "additions, subtractions, similarity = compare_texts_spacy(normalized_official_text, normalized_transcribed_text)\n",
    "\n",
    "# Save the differences and similarity to a txt file\n",
    "save_differences(additions, subtractions, similarity, output_txt_path)\n",
    "\n",
    "print(f\"Comparison complete. Results saved to {output_txt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Brillitt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Brillitt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similitud entre los dos documentos es: 92.29%\n",
      "Las diferencias se han guardado en transcripcion/ppk/diff_output.txt\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Descargar stopwords de nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Función para extraer texto de un PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            text += reader.pages[page_num].extract_text()\n",
    "    return text\n",
    "\n",
    "# Función para preprocesar el texto\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens if word.isalnum() and word.lower() not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Función para calcular la similitud entre dos documentos\n",
    "def calculate_similarity(doc1, doc2):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([doc1, doc2])\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "    return similarity_matrix[0, 1]\n",
    "\n",
    "def find_differences(text1, text2, output_file):\n",
    "    diff = difflib.ndiff(text1.split(), text2.split())\n",
    "    differences = [line for line in diff if line.startswith('- ') or line.startswith('+ ')]\n",
    "    with open(output_file, 'w') as file:\n",
    "        for line in differences:\n",
    "            file.write(line + '\\n')\n",
    "            \n",
    "# Rutas a los archivos PDF\n",
    "pdf_path1 = 'transcripcion/ppk/transcripcion_literal.pdf'\n",
    "pdf_path2 = 'transcripcion/ppk/transcripcion_ia.pdf'\n",
    "output_file = \"transcripcion/ppk/diff_output.txt\"\n",
    "\n",
    "# Extraer y preprocesar el texto de los PDFs\n",
    "text1 = extract_text_from_pdf(pdf_path1)\n",
    "text2 = extract_text_from_pdf(pdf_path2)\n",
    "preprocessed_text1 = preprocess_text(text1)\n",
    "preprocessed_text2 = preprocess_text(text2)\n",
    "\n",
    "# Calcular la similitud\n",
    "similarity = calculate_similarity(preprocessed_text1, preprocessed_text2)\n",
    "print(f'La similitud entre los dos documentos es: {similarity*100:.2f}%')\n",
    "\n",
    "# Encontrar diferencias y guardarlas en un archivo\n",
    "find_differences(preprocessed_text1, preprocessed_text2, output_file)\n",
    "print(f'Las diferencias se han guardado en {output_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
